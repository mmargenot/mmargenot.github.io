<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Graphs on this is a website for thinking</title>
    <link>http://localhost:1313/tags/graphs/</link>
    <description>Recent content in Graphs on this is a website for thinking</description>
    <generator>Hugo -- 0.145.0</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 30 Mar 2025 19:01:59 -0400</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/graphs/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Benchmarking Graph Embeddings on Small Data</title>
      <link>http://localhost:1313/posts/benchmarking-graph-embeddings-on-small-data/</link>
      <pubDate>Sun, 30 Mar 2025 19:01:59 -0400</pubDate>
      <guid>http://localhost:1313/posts/benchmarking-graph-embeddings-on-small-data/</guid>
      <description>&lt;p&gt;When I read papers on embeddings, I see vectors trained on a massive scale, with huge data. Text from &lt;a href=&#34;https://pile.eleuther.ai/&#34;&gt;The Pile&lt;/a&gt;, web crawl data from &lt;a href=&#34;https://commoncrawl.org/&#34;&gt;Common Crawl&lt;/a&gt;, articles from &lt;a href=&#34;https://wikipedia.org/&#34;&gt;Wikipedia&lt;/a&gt;, data on a scale that could not possibly be replicated by a single human person. The language models that result from these efforts are a triumph of engineering, and lay the foundation for something that I am passionate about: Models on a human scale.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Graph Embeddings on a Personal Scale</title>
      <link>http://localhost:1313/posts/graph-embeddings-on-a-personal-scale/</link>
      <pubDate>Sun, 30 Mar 2025 17:01:13 -0400</pubDate>
      <guid>http://localhost:1313/posts/graph-embeddings-on-a-personal-scale/</guid>
      <description>&lt;p&gt;Tech giants collect data at a massive scale to power their proudcts. The &lt;a href=&#34;https://en.wikipedia.org/wiki/Google_Knowledge_Graph&#34;&gt;Google knowledge graph&lt;/a&gt; contains 570 million nodes and 18 billion edges and, back in the day, part of the Facebook social graph, included &lt;a href=&#34;https://research.facebook.com/publications/one-trillion-edges-graph-processing-at-facebook-scale/&#34;&gt;1 trillion edges&lt;/a&gt;. Information at this scale is impossible to fathom for an individual, it is the aggregate of activity of billions of people, but the structures that are used to organize this information can also be used to organize your own thoughts.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
